{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429252f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['STATEFP', 'COUNTYFP', 'COUNTYNS', 'GEOID', 'NAME', 'NAMELSAD', 'LSAD',\n",
      "       'CLASSFP', 'MTFCC', 'CSAFP', 'CBSAFP', 'METDIVFP', 'FUNCSTAT', 'ALAND',\n",
      "       'AWATER', 'INTPTLAT', 'INTPTLON', 'Shape_Leng', 'Shape_Area',\n",
      "       'geometry'],\n",
      "      dtype='object')\n",
      "county\n",
      "Los Angeles    5824\n",
      "Orange         1618\n",
      "San Diego      1609\n",
      "Alameda        1017\n",
      "Santa Clara    1003\n",
      "Name: count, dtype: int64\n",
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value', 'ocean_proximity', 'county_Alameda',\n",
      "       'county_Alpine', 'county_Amador', 'county_Butte', 'county_Calaveras',\n",
      "       'county_Colusa', 'county_Contra Costa', 'county_Del Norte',\n",
      "       'county_El Dorado', 'county_Fresno', 'county_Glenn', 'county_Humboldt',\n",
      "       'county_Imperial', 'county_Inyo', 'county_Kern', 'county_Kings',\n",
      "       'county_Lake', 'county_Lassen', 'county_Los Angeles', 'county_Madera',\n",
      "       'county_Marin', 'county_Mariposa', 'county_Mendocino', 'county_Merced',\n",
      "       'county_Modoc', 'county_Mono', 'county_Monterey', 'county_Napa',\n",
      "       'county_Nevada', 'county_Orange', 'county_Placer', 'county_Plumas',\n",
      "       'county_Riverside', 'county_Sacramento', 'county_San Benito',\n",
      "       'county_San Bernardino', 'county_San Diego', 'county_San Francisco',\n",
      "       'county_San Joaquin', 'county_San Luis Obispo', 'county_San Mateo',\n",
      "       'county_Santa Barbara', 'county_Santa Clara', 'county_Santa Cruz',\n",
      "       'county_Shasta', 'county_Sierra', 'county_Siskiyou', 'county_Solano',\n",
      "       'county_Sonoma', 'county_Stanislaus', 'county_Sutter', 'county_Tehama',\n",
      "       'county_Trinity', 'county_Tulare', 'county_Tuolumne', 'county_Ventura',\n",
      "       'county_Yolo', 'county_Yuba'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBRegressor\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.metrics import make_scorer\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Wczytaj dane\n",
    "df = pd.read_csv(\"data/housing.csv\")\n",
    "\n",
    "#geometry data\n",
    "gdf_points = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df.longitude, df.latitude),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "gdf_county = gpd.read_file(\"data/geodata/CA_Counties.shp\")  # shapefile z opisem hrabstw\n",
    "gdf_county = gdf_county.to_crs(\"EPSG:4326\")  # ujednolicenie CRS :contentReference[oaicite:6]{index=6}\n",
    "\n",
    "print(gdf_county.columns)\n",
    "\n",
    "gdf_joined = gpd.sjoin(\n",
    "    gdf_points,\n",
    "    gdf_county[['geometry', 'NAME']],  # zmień 'NAME' jeśli inna kolumna zawiera nazwę hrabstwa\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "\n",
    "gdf_joined[\"county\"] = gdf_joined[\"NAME\"]\n",
    "\n",
    "print(gdf_joined[\"county\"].value_counts().head())\n",
    "\n",
    "df_model = gdf_joined.drop(columns=[\"geometry\", \"index_right\", \"NAME\"])  # zależnie od wersji geopandas\n",
    "\n",
    "df_model = pd.get_dummies(df_model, columns=[\"county\"], prefix=\"county\")\n",
    "\n",
    "print(df_model.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFeaturesAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.median_total_bedrooms = X[\"total_bedrooms\"].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"total_bedrooms\"] = X[\"total_bedrooms\"].fillna(self.median_total_bedrooms)\n",
    "        X[\"rooms_per_household\"] = X[\"total_rooms\"] / X[\"households\"]\n",
    "        X[\"bedrooms_per_room\"] = X[\"total_bedrooms\"] / X[\"total_rooms\"]\n",
    "        X[\"population_per_household\"] = X[\"population\"] / X[\"households\"]\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_model.copy()\n",
    "\n",
    "# Wypełnij braki medianą\n",
    "df[\"total_bedrooms\"].fillna(df[\"total_bedrooms\"].median(), inplace=True)\n",
    "df[\"rooms_per_household\"] = df[\"total_rooms\"] / df[\"households\"]\n",
    "df[\"bedrooms_per_room\"] = df[\"total_bedrooms\"] / df[\"total_rooms\"]\n",
    "df[\"population_per_household\"] = df[\"population\"] / df[\"households\"]\n",
    "\n",
    "\n",
    "log_cols = [\"median_income\", \"population\", \"households\", \"median_house_value\"]\n",
    "for col in log_cols:\n",
    "    df[col] = np.log1p(df[col])\n",
    "\n",
    "# Teraz usuwamy surowe latitude i longitude\n",
    "df.drop([\"latitude\", \"longitude\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffd065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yayec\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\yayec\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Results (on original scale):\n",
      "MAE : 40,532.65\n",
      "RMSE: 60,154.24\n",
      "R²  : 0.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yayec\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Results (on original scale):\n",
      "MAE : 41,863.95\n",
      "RMSE: 61,547.72\n",
      "R²  : 0.7109\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dane wejściowe i wyjściowe\n",
    "X = df.drop(\"median_house_value\", axis=1)\n",
    "y = df[\"median_house_value\"]\n",
    "\n",
    "# 5. Identyfikacja cech numerycznych i kategorycznych\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "\n",
    "# 5. Identyfikacja cech numerycznych i kategorycznych\n",
    "num_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# 6. Pipeline preprocessingu\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numerical_pipeline, num_cols),\n",
    "    (\"cat\", categorical_pipeline, cat_cols)\n",
    "])\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "\n",
    "# --- Modele ---\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "xgb = XGBRegressor(random_state=42, verbosity=0)\n",
    "\n",
    "# --- Pipeline Random Forest ---\n",
    "pipeline_rf = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", rf)\n",
    "])\n",
    "\n",
    "# --- Pipeline XGBoost ---\n",
    "pipeline_xgb = Pipeline([\n",
    "    (\"preprocessing\", preprocessor),\n",
    "    (\"model\", xgb)\n",
    "])\n",
    "\n",
    "# --- Podział na train/test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Trening i ewaluacja z odlogarytmowaniem ---\n",
    "def evaluate_model(pipeline, name=\"Model\"):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred_log = pipeline.predict(X_test)\n",
    "    \n",
    "    # Odlogarytmowanie\n",
    "    y_test_exp = np.expm1(y_test)\n",
    "    y_pred_exp = np.expm1(y_pred_log)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test_exp, y_pred_exp)\n",
    "    rmse = mean_squared_error(y_test_exp, y_pred_exp, squared=False)\n",
    "    r2 = r2_score(y_test_exp, y_pred_exp)\n",
    "    \n",
    "    print(f\"\\n{name} Results (on original scale):\")\n",
    "    print(f\"MAE : {mae:,.2f}\")\n",
    "    print(f\"RMSE: {rmse:,.2f}\")\n",
    "    print(f\"R²  : {r2:.4f}\")\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# Trening i ocena\n",
    "model_rf = evaluate_model(pipeline_rf, \"Random Forest\")\n",
    "model_xgb = evaluate_model(pipeline_xgb, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163b1869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_pipeline.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Zapisz pipeline do pliku\n",
    "joblib.dump(model_xgb, \"xgb_pipeline.pkl\")\n",
    "joblib.dump(model_rf, \"rf_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c8c5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        452600.0\n",
      "1        358500.0\n",
      "2        352100.0\n",
      "3        341300.0\n",
      "4        342200.0\n",
      "           ...   \n",
      "20635     78100.0\n",
      "20636     77100.0\n",
      "20637     92300.0\n",
      "20638     84700.0\n",
      "20639     89400.0\n",
      "Name: median_house_value, Length: 20640, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"median_house_value\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
